{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ec9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modeling and Forecasting\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9357bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('file3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5eb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows with missing values: {data.isnull().any(axis=1).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data = data.set_index('date')\n",
    "data = data.rename(columns={'_Positive': 'y'})\n",
    "data = data.asfreq('D')\n",
    "data = data.sort_index()\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data['y'].plot(ax=ax, label='data_NAN')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745abb5c",
   "metadata": {},
   "source": [
    "We use linear interpolation to capture the missing values in the DataFrame. This method fills in missing values by predicting them based on a linear relationship between adjacent data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfbf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.interpolate(method='linear') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data['y'].plot(ax=ax, label='data')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b30218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that a temporary index is complete\n",
    "\n",
    "(data.index == pd.date_range(start=data.index.min(),\n",
    "                             end=data.index.max(),\n",
    "                             freq=data.index.freq)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2061ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Object StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply normalization to time series data\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Convert the result back to Ð² DataFrame\n",
    "data_normalized = pd.DataFrame(data_normalized, index=data.index, columns=data.columns)\n",
    "data_normalized.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ace215",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test\n",
    "\n",
    "steps = 7\n",
    "data_train = data[:-steps]\n",
    "data_test  = data[-steps:]\n",
    "\n",
    "print(f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags = 6\n",
    "                )\n",
    "\n",
    "forecaster.fit(y=data_train['y'])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4330882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "steps = 7\n",
    "predictions = forecaster.predict(steps=steps)\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64878f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "predictions.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75836390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error\n",
    "\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['y'],\n",
    "                y_pred = predictions\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid search\n",
    "\n",
    "steps = 7\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 12 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [10, 20]\n",
    "\n",
    "# Regressor's hyperparameters\n",
    "param_grid = {'n_estimators': [100, 500],\n",
    "              'max_depth': [3, 5, 10]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data_train['y'],\n",
    "                        param_grid         = param_grid,\n",
    "                        lags_grid          = lags_grid,\n",
    "                        steps              = steps,\n",
    "                        refit              = True,\n",
    "                        metric             = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(data_train)*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search results\n",
    "\n",
    "results_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927d3b4",
   "metadata": {},
   "source": [
    "# Final model\n",
    "Finally, a ForecasterAutoreg is trained with the optimal configuration found by validation. This step is not necessary if return_best = True is specified in the grid_search_forecaster function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with the best hyperparameters\n",
    "\n",
    "regressor = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=123)\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = regressor,\n",
    "                lags      = 5\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "predictions = forecaster.predict(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "predictions.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be93962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error\n",
    "\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['y'],\n",
    "                y_pred = predictions\n",
    "                )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c607d",
   "metadata": {},
   "source": [
    "## Prediction for the future (30 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150950fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test\n",
    "\n",
    "steps = 30\n",
    "data_train = data[:-steps]\n",
    "data_test  = data[-steps:]\n",
    "\n",
    "print(f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7236bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags = 30\n",
    "                )\n",
    "\n",
    "forecaster.fit(y=data_train['y'])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81891cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on 30 days\n",
    "\n",
    "steps = 30\n",
    "predictions_30 = forecaster.predict(steps=steps)\n",
    "predictions_30.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94917078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "predictions_30.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error\n",
    "\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['y'],\n",
    "                y_pred = predictions_30\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ab375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid search\n",
    "\n",
    "steps = 30\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 30 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [10, 20]\n",
    "\n",
    "# Regressor's hyperparameters\n",
    "param_grid = {'n_estimators': [100, 500],\n",
    "              'max_depth': [3, 5, 10]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data_train['y'],\n",
    "                        param_grid         = param_grid,\n",
    "                        lags_grid          = lags_grid,\n",
    "                        steps              = steps,\n",
    "                        refit              = True,\n",
    "                        metric             = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(data_train)*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search results\n",
    "\n",
    "results_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc11299",
   "metadata": {},
   "source": [
    "## Final model\n",
    "Finally, a ForecasterAutoreg is trained with the optimal configuration found by validation. This step is not necessary if return_best = True is specified in the grid_search_forecaster function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with the best hyperparameters\n",
    "\n",
    "regressor = RandomForestRegressor(max_depth=3, n_estimators=100, random_state=123)\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = regressor,\n",
    "                lags      = 30\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c69749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "predictions_30 = forecaster.predict(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3cbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "predictions_30.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ddb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error\n",
    "\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['y'],\n",
    "                y_pred = predictions_30\n",
    "                )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5242fe3",
   "metadata": {},
   "source": [
    "# Prediction for the future (30 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test\n",
    "\n",
    "steps = 90\n",
    "data_train = data[:-steps]\n",
    "data_test  = data[-steps:]\n",
    "\n",
    "print(f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77a47d26",
   "metadata": {},
   "source": [
    "# Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "predictions_90.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d01368f8",
   "metadata": {},
   "source": [
    "# Test error\n",
    "\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['y'],\n",
    "                y_pred = predictions_90\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d57e4b6",
   "metadata": {},
   "source": [
    "# Hyperparameter Grid search\n",
    "\n",
    "steps = 90\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 90 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [10, 20]\n",
    "\n",
    "# Regressor's hyperparameters\n",
    "param_grid = {'n_estimators': [100, 500],\n",
    "              'max_depth': [3, 5, 10]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data_train['y'],\n",
    "                        param_grid         = param_grid,\n",
    "                        lags_grid          = lags_grid,\n",
    "                        steps              = steps,\n",
    "                        refit              = True,\n",
    "                        metric             = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(data_train)*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b5407a4",
   "metadata": {},
   "source": [
    "# Grid Search results\n",
    "\n",
    "results_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e833b52e",
   "metadata": {},
   "source": [
    "## Final model\n",
    "Finally, a ForecasterAutoreg is trained with the optimal configuration found by validation. This step is not necessary if return_best = True is specified in the grid_search_forecaster function."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0898604",
   "metadata": {},
   "source": [
    "# Create and train forecaster with the best hyperparameters\n",
    "\n",
    "regressor = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=123)\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = regressor,\n",
    "                lags      = 5\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data_train['y'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67dca685",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "predictions_90 = forecaster.predict(steps=steps)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99c80e13",
   "metadata": {},
   "source": [
    " Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "predictions_90.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d23288",
   "metadata": {},
   "source": [
    "# Test error\n",
    "\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['y'],\n",
    "                y_pred = predictions_90\n",
    "                )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95eacf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b4763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_normalized\n",
    "steps = 7\n",
    "data_train = data[:-steps]\n",
    "data_test  = data[-steps:]\n",
    "\n",
    "print(f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data_train['y'].plot(ax=ax, label='train')\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df946497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster\n",
    "# ==============================================================================\n",
    "orecaster = ForecasterAutoreg(\n",
    "                    regressor = LinearRegression(),\n",
    "                    lags = 7\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data_train['y'])\n",
    "\n",
    "# Prediction intervals\n",
    "# ==============================================================================\n",
    "predictions = forecaster.predict_interval(\n",
    "                    steps    = steps,\n",
    "                    interval = [1, 99],\n",
    "                    n_boot   = 500\n",
    "              )\n",
    "\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction error\n",
    "\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['y'],\n",
    "                y_pred = predictions.iloc[:, 0]\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data_test['y'].plot(ax=ax, label='test')\n",
    "predictions['pred'].plot(ax=ax, label='prediction')\n",
    "ax.fill_between(\n",
    "    predictions.index,\n",
    "    predictions['lower_bound'],\n",
    "    predictions['upper_bound'],\n",
    "    color = 'red',\n",
    "    alpha = 0.2\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b98c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest with prediction intervals\n",
    "\n",
    "n_backtesting = 7*3 \n",
    "steps = 7\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3\n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                            forecaster         = forecaster,\n",
    "                            y                  = data['y'],\n",
    "                            initial_train_size = len(data) - n_backtesting,\n",
    "                            fixed_train_size   = False,\n",
    "                            steps              = steps,\n",
    "                            metric             = 'mean_squared_error',\n",
    "                            refit              = True,\n",
    "                            interval           = [1, 99],\n",
    "                            n_boot             = 100,\n",
    "                            verbose            = True\n",
    "                      )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "data.loc[predictions.index, 'y'].plot(ax=ax, label='test')\n",
    "predictions['pred'].plot(ax=ax, label='predicciones')\n",
    "ax.fill_between(\n",
    "    predictions.index,\n",
    "    predictions['lower_bound'],\n",
    "    predictions['upper_bound'],\n",
    "    color = 'red',\n",
    "    alpha = 0.2\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted interval coverage\n",
    "\n",
    "inside_interval = np.where(\n",
    "                     (data.loc[predictions.index, 'y'] >= predictions['lower_bound']) & \\\n",
    "                     (data.loc[predictions.index, 'y'] <= predictions['upper_bound']),\n",
    "                     True,\n",
    "                     False\n",
    "                   )\n",
    "\n",
    "coverage = inside_interval.mean()\n",
    "print(f\"Predicted interval coverage: {round(100*coverage, 2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d80a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
